\section{Lezione 06 - 24-03-2023}

\subsection{Propietà Sottospazio Vettoriale}

\begin{itemize}
\item[$W \underline{<} V$ è stabile rispetto alla somma di $n$ oggetti]
Siano $\underline{w}_1, ... , \underline{w}_n \in W$ si ha $w_1 + w_2 \in W \Rightarrow$ 
\item[Famiglia di sottospazi vettoriali]
Sia $ \mathbb{L}$ una famiglia di sottospazi di $V$, l'intersezione dei sottospazi della famiglia $\mathbb{L}$ è un sottospazio e si indica: 
$$ \bigcap_{L \in \mathbb{L}} L $$
L'intersezione di una qualunque famiglia di sottospazi è un sottospazio.\\
Dimostriamolo: 
	\subitem Neutro: Il neutro è un elemento comune, quindi è sempre contenuto.
	\subitem Stab $+$: Siano $ \underline{v},\underline{w} \in \bigcap_{L \in \mathbb{L}} L \Rightarrow \forall L \in \mathbb{L} \Rightarrow \underline{v},\underline{w} \in L \Rightarrow \underline{v}+\underline{w} \in \bigcap_{L \in \mathbb{L}} L $
	\subitem Stab $\cdot$: Siano $ \underline{v} \in \bigcap_{L \in \mathbb{L}} L, h \in \mathbb{R} \Rightarrow \forall L \in \mathbb{L} \Rightarrow \underline{v},\underline{w} \in L \Rightarrow \underline{v}+\underline{w} \in \bigcap_{L \in \mathbb{L}} L $
\end{itemize}

\subsection{Sottospazio Generato}
Sia $ S \subseteq V $, indicheremo con $<S>$ il \textbf{sotto spazio generato da S}.\\
$$ <S> = \bigcap_{L \in \mathbb{L}_s} L $$ 
$$ \mathbb{L}_s = \{W \underline{<} V / S \subseteq W \} $$
$$ \textbf{Intersezione dei sottospazi di V che contengono S} $$
In altri termini: è il più piccolo sottospazio rispetto all'intersezione.

\subsubsection{Esempi}
Poniamo $ H \underline{<} V $
\begin{itemize}
\item[•] $ <H> = H $ SEMPRE!
\item[•] $ <\{\underline{0}\} = \{\underline{0}\} $
\item[•] $ <V> = V $ 
\item[•] $ <\emptyset> = {0} $ Singleton dell'elemento neutro, poiché appartiene ad ogni elemento.
\end{itemize}

\subsection{Casi di Sottospazi Generati}

$ S= H \cup K $ con $H,K \underline{<} V$
$$ <H \cup K> = H+K = \{\underline{h}+\underline{k} / \underline{h} \in H, \underline{k} \in K \} $$
Dim:
Come sempre per dimostrare l'uguaglianza dobbiamo dimostare la doppia inclusione:
$$ <H \cup K> \subseteq \textbf{al contrario } H+K = \{\underline{h}+\underline{k} / \underline{h} \in H, \underline{k} \in K \} $$
non ho capito\\

Dimostriamo che sia spazio vettoriale:
\begin{itemize}
\item[Neutro] $$ \underline{0} = \underline{0}^{\text{preso da H}} + \underline{0}^{\text{preso da K}} $$
\item[Stabile $+$] $$ (\underline{h} + \underline{k}) + (\underline{h}^{'} + \underline{k}^{'}) \in H+K $$
$$ (h+h^{'}) + (k+k^{'}) $$
\item[Stabile $\cdot$] $$ \alpha(\underline{h}+\underline{k}) = \alpha\underline{h} + \alpha \underline{k}  $$
\end{itemize}

\subsubsection{Esempio}
$$ H=\{(0,k) / x \in \mathbb{R}\} \;\;\; K=\{(y,0) / y \in \mathbb{R} \} $$
$$ <H \cup K> = H+K = (0+y, x+0) = \mathbb{R}^2 $$

\subsection{Propietà Sottospazio Generato}
Posto $H,K \underline{<} V$, allora valgono le seguenti propietà:
\begin{itemize}
\item[•] $ H \oplus K \; \textbf{si dicono in somma diretta se} \; H \cap K = \{ \underline{0} \} \;(\text{neutro}) $
\item[•] $ H + K = V$ allora $H,K$ si dicono supplementari
\item[•] $ H \oplus K = V$ allora si dicono complementari (in altri termini devono essere in somma diretta e supplementari).\footnote{È un concetto un po' strano, perché vuol dire somma normale (quindi caso 2), ma ricordandoci che l'intersezione da il neutro (quindi caso 1)}
\end{itemize}

\subsubsection{Esempio}
Posti $\{ \underline{0} \}$ e $V$:
\begin{itemize}
\item[]Somma diretta: $ \{ \underline{0} \} \oplus V = \{ \underline{0} \} \cap V = \{ \underline{0} \}$
\item[]Supplementari: $  \{ \underline{0} \} + V = V$
\item[]Complementare: Dato che è sia somma diretta che supplementare
\end{itemize}
In generale, $ H \underline{<} K \Rightarrow H + K = K $\\

Ponendoci in $\mathbb{R}^3[x]$ e presi $\mathbb{R}^2[x], \mathbb{R}^3[x] \underline{<} \mathbb{R}^3[x]$, possiamo dire:
\begin{itemize}
\item[•] NON Somma diretta: $ \mathbb{R}^2[x] \oplus \mathbb{R}^3[x] \neq \{ \underline{0}\} $
\item[•] Supplementari: $ \mathbb{R}^2[x] + \mathbb{R}^3[x] = \mathbb{R}^3[x]$
\item[•] Complementari: no poiché manca la somma diretta.
\end{itemize}


Ponendoci invece $\mathbb{R}^4[x]$ e presi $\mathbb{R}^2[x], \mathbb{R}^3[x] \underline{<} \mathbb{R}^3[x]$, possiamo dire:
\begin{itemize}
\item[•] NON Somma diretta: $ \mathbb{R}^2[x] \oplus \mathbb{R}^3[x] \neq \{ \underline{0}\} $
\item[•] NON Supplementari: $ \mathbb{R}^2[x] + \mathbb{R}^3[x] = \mathbb{R}^3[x] \neq \mathbb{R}^4[x]$
\item[•] Complementari: no poiché manca la somma diretta.
\end{itemize}


\subsection{Dipendenza/Indipendenza Lineare}
Sia $V$ uno spazio vettoriale e siano $\underline{v}_1, \underline{v}_2, ..., \underline{v} \in V$, sono detti \textbf{linearmente dipendenti} (o legati) $\Leftrightarrow$
$$ \exists \alpha_1, \alpha_2, ..., \alpha_n \neq (0,0,...,0) = \alpha_1\underline{v_1} + ... + \alpha_n+\underline{v}_n = \underline{0}$$
La loro combinazione lineare deve essere il vettore nullo.
Se tali scalari non esistono allora si dice che sono \textbf{linearmente indipendenti} (o liberi), l'unica soluzione valida è quella formata da tutti zero: $0\underline{v}_1+...+0\underline{v}_n = \underline{0}$.
$$ \textbf{Se non sono dipendenti} \Rightarrow \textbf{Sono indipendenti}$$

\subsubsection{Esempio}
Posto $ \mathbb{R}^2 $ facciamo i seguenti esempi:
$$ (1,1),(1,0),(3,0) \; \textbf{sono dipendenti} \; 0(1,1)+(-3)(1,0)+1(3,0) = (0,0) $$
$$ (1,1),(1,0) \; \textbf{sono indipendenti} \; x(1,1) + y(1,0) = (0,0) \; \text{MA unica soluzione possibile (0,0) quindi sono indipendendenti} $$

\subsection{Propietà dipendenza lineare}
\begin{itemize}
\item[1)] $\underline{0}$ dipende sempre da qualunque sistema
$$ \underline{0} = 0\underline{v}_1+...+0\underline{v}_n $$
\item[2)] Sia $\underline{v}$ dipendente da $\underline{v}_1,...,\underline{v}_n$ e ciascun $\underline{v}_i$ dipende da $\underline{w}_1,...,\underline{w}_m \Rightarrow \underline{v} $ dipende da $\underline{w}_1,...,\underline{w}_m$ \footnote{Una specie di transitività della dipendenza} \\
Dim: \\
$$ \underline{v} = \alpha_1\underline{v}_1 + ... + \alpha_n\underline{v}_n \; \text{(dipende come da tesi)}$$
$$ \forall i, \: \underline{v}_i = \beta_{i,1} \underline{w}_1 + ... + \beta_{i,m} \underline{w}_n \text{(ogni $v_i$ dipende a sua volta da un $w_i$)}$$
$$ \underline{v} = \alpha_1(\beta_{i,1} \underline{w}_1 + ... + \beta_{i,m} \underline{w}_n) + ... + \alpha_n (\beta_{n,1} \underline{w}_1 + ... + \beta_{n,m} \underline{w}_n) $$
$$ \underline{v} = \gamma_1\underline{w_1} + ... + \gamma_m \underline{w}_m \text{(compattiamo)}$$
\item[3)] $\underline{v}_i$ dipende da $\underline{v}_1,...,\underline{v}_n$ 
$$ \underline{v}_i = 0\underline{v}_1 + ... + 0\underline{v}_n $$
\item[4)] $ \underline{v}, \underline{w} $ dipende da $\underline{v}_1,...,\underline{v}_n \Rightarrow \underline{v}+\underline{w} $ dipende da $\underline{v}_1,...,\underline{v}_n$\\
Dim:\\
$$ \underline{v} = \alpha_1\underline{v}_1 + ... + \alpha_n\underline{v}_n $$
$$ \underline{w} = \beta_1\underline{w}_1 + ... + \beta_n\underline{w}_n $$
$$ \underline{v} + \underline{w} = (\alpha_1 + \beta_1)\underline{v}_1 + ... + (\alpha_n + \beta_n)\underline{v}_n $$
\item[5)] $ \underline{v} $ dipende da $\underline{v}_1,...,\underline{v}_n \Rightarrow h\underline{v} $ dipende da $\underline{v}_1,...,\underline{v}_n$

\subsection{Relazione con la Generazione}
Posti $\underline{v}_1,...,\underline{v}_n \in V$ allora:
$$ <\underline{v}_1,...,\underline{v}_n> = \{h_1\underline{v}_1,...,h_n\underline{v}_n / h_i \in R \} \; \textbf{Copertura Lineare}$$
In altre parole:
$$ \underline{v} \in <\underline{v}_1,...,\underline{v}_n> \:\text{se}\: \underline{v} \: \text{dipende dai vettori} \: \underline{v}_1,...,\underline{v}_n  $$
Dim sottospazio:
\begin{itemize}
\item[•] Neutro: vale per la $1)$ 
\item[•] Stabile $+$: vale per la $4)$
\item[•] Stabile $\cdot$: vale per la $5)$
\end{itemize}

\subsubsection{Esempio}
boh non si è capito nulla in classe


\end{itemize}







